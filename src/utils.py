import os
import re
import xml.etree.ElementTree as ET
import base64
from urllib.parse import unquote #, urljoin, quote
import aiohttp
import chardet
#from bs4 import BeautifulSoup

from constants import CRITERIA_PATTERN, CRITERIA_PATTERN_SERIES_QUOTED #FLIBUSTA_BASE_URL

#from html import unescape
#from constants import FLIBUSTA_BASE_URL

# –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω FB2
FB2_NAMESPACE = "http://www.gribuser.ru/xml/fictionbook/2.0"
XLINK_NAMESPACE = "http://www.w3.org/1999/xlink"

# –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞–º–∏ –∏–º–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ XPath
NAMESPACES = {
    "fb": FB2_NAMESPACE,
    "xlink": XLINK_NAMESPACE,
}

# –ò–º—è –±–æ—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
BOT_USERNAME = os.getenv("BOT_USERNAME", "")

def format_size(size_in_bytes):
    units = ["B", "K", "M", "G", "T"]
    unit_index = 0
    while size_in_bytes >= 1024 and unit_index < len(units) - 1:
        size_in_bytes /= 1024
        unit_index += 1
    return f"{size_in_bytes:.1f}{units[unit_index]}"

#def split_query_into_words(query):
#    keywords = ["–∞–≤—Ç–æ—Ä", "–Ω–∞–∑–≤–∞–Ω–∏–µ", "–∂–∞–Ω—Ä", "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ø–∏—Å–∞—Ç–µ–ª—å", "–∏–∑–¥–∞—Ç–µ–ª—å"]
#    for keyword in keywords:
#        query = query.replace(keyword, "")
#    return [word.strip() for word in query.split() if len(word.strip()) > 1]

def split_word_by_control_sign(source_word):
    word = source_word.strip()
    operator = 'LIKE' # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LIKE
    if len(word) > 1:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø–µ—Ä–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        if word.startswith('!'):
            operator = '<>'
            word = word[1:]  # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª '!'
        elif word.startswith('='):
            operator = '='
            word = word[1:]  # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª '='
        elif word.startswith('~'):
            operator = 'NOT LIKE'
            word = word[1:]  # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª '~'

    return word, operator

def split_query_into_words(query):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–ª–æ–≤–∞, —É—á–∏—Ç—ã–≤–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å–ª–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Å–ª–æ–≤–æ, –æ–ø–µ—Ä–∞—Ç–æ—Ä).
    """
    #keywords = ["–∞–≤—Ç–æ—Ä", "–Ω–∞–∑–≤–∞–Ω–∏–µ", "–∂–∞–Ω—Ä", "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ø–∏—Å–∞—Ç–µ–ª—å"]
    #for keyword in keywords:
    #    query = query.replace(keyword, "")

    words = []
    for word in query.split():
        word = word.strip()
        if len(word) > 1:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø–µ—Ä–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            word, operator = split_word_by_control_sign(word)
            words.append((word, operator))
    return words

def extract_criteria(text):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∏ —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.
    –°–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–µ–≤–∞ –∏–ª–∏ —Å–ø—Ä–∞–≤–∞ –æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.
    """
    text = text.strip()
    if not text:
        return []

    # pattern = re.compile(CRITERIA_PATTERN, re.IGNORECASE)
    # # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    # matches = list(re.finditer(pattern, text))

    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Å–µ—Ä–∏–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
    series_quoted_pattern = re.compile(CRITERIA_PATTERN_SERIES_QUOTED, re.IGNORECASE)
    series_quoted_matches = list(re.finditer(series_quoted_pattern, text))

    # –£–±–∏—Ä–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–µ—Ä–∏–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
    text_without_quoted_series = text
    for match in series_quoted_matches:
        text_without_quoted_series = text_without_quoted_series.replace(match.group(0), '')

    # –ó–∞—Ç–µ–º –∏—â–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    all_pattern = re.compile(CRITERIA_PATTERN, re.IGNORECASE)
    all_matches = list(re.finditer(all_pattern, text_without_quoted_series))

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –ø–µ—Ä–≤–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
    all_matches = series_quoted_matches + all_matches
    all_matches.sort(key=lambda x: x.start())

    if not all_matches:
        # –ù–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ - –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å–≤–æ–±–æ–¥–Ω—ã–π
        return []

    #debug
    print(all_matches)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –ø–µ—Ä–≤–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
    first_match_start = all_matches[0].start()
    last_match_end = all_matches[-1].end()

    # –°–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–µ–≤–∞ –æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    free_text_left = text[:first_match_start].strip()
    free_text_left = free_text_left.strip(' ,;')

    # –°–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ø—Ä–∞–≤–∞ –æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    free_text_right = text[last_match_end:].strip()
    free_text_right = free_text_right.strip(' ,;')

    free_text = free_text_left if free_text_left else free_text_right

    criteria_values = []
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –∫—Ä–∏—Ç–µ—Ä–∏–π "–ø–æ–ª–Ω—ã–π"
    if free_text:
        criteria_values.insert(0, ('–ø–æ–ª–Ω—ã–π', free_text))

    # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∏–∑ matches
    for match in all_matches:
        criterion = match.group(1).lower()
        value = match.group(2).strip()
        criteria_values.append((criterion, value))

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–≤–∫–ª—é—á–∞—è –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π "–ø–æ–ª–Ω—ã–π")
    results = []
    for criterion, value in criteria_values:
        criterion = criterion.lower()
        value = value.strip()

        # –û—Å–æ–±–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏—è "—Å–µ—Ä–∏—è" —Å –∫–∞–≤—ã—á–∫–∞–º–∏
        if criterion == '—Å–µ—Ä–∏—è' and (value.startswith('"') and value.endswith('"') or
                                     value.startswith("'") and value.endswith("'")):
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —Å–µ—Ä–∏–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
            exact_value = value[1:-1].strip()  # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏
            results.append((criterion, exact_value, '=', 'AND'))
        elif criterion == '–≥–æ–¥':
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≥–æ–¥–∞
            if '-' in value:
                if value.startswith('-'):
                    # –§–æ—Ä–º–∞—Ç: -2021 (–¥–æ 2021)
                    results.append((criterion, value[1:], '<=', 'AND'))
                elif value.endswith('-'):
                    # –§–æ—Ä–º–∞—Ç: 2021- (–æ—Ç 2021)
                    results.append((criterion, value[:-1], '>=', 'AND'))
                else:
                    # –§–æ—Ä–º–∞—Ç: 2021-2023 (–¥–∏–∞–ø–∞–∑–æ–Ω)
                    year_from, year_to = value.split('-')
                    results.append((criterion, year_from, '>=', 'AND'))
                    results.append((criterion, year_to, '<=', 'AND'))
            else:
                # –¢–æ—á–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –≥–æ–¥
                results.append((criterion, value, '=', 'AND'))
        else:
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–∞–≤—Ç–æ—Ä, –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ç.–¥.)
            #word, operator = split_word_by_control_sign(value)
            #results.append((criterion, word, operator))

            #words = split_query_into_words(value)
            #for word, operator in words:
            #    results.append((criterion, word, operator))

            # –†–∞–∑–±–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ "|" –¥–ª—è OR-—É—Å–ª–æ–≤–∏–π
            or_parts = [part.strip() for part in value.split('|') if part.strip()]
            for part in or_parts:
                words = split_query_into_words(part)
                for word, operator in words:
                    results.append((criterion, word, operator, 'OR' if len(or_parts) > 1 else 'AND'))

    return results

def extract_cover_from_fb2(file):
    try:
        # –ø–∞—Ä—Å–∏–º FB2 —Ñ–∞–π–ª
        tree = ET.parse(file)
        root = tree.getroot()

        # –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±–ª–æ–∂–∫—É
        cover_element = root.find(".//fb:coverpage/fb:image", namespaces=NAMESPACES)
        if cover_element is None:
            raise ValueError("–û–±–ª–æ–∂–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ FB2-—Ñ–∞–π–ª–µ.")

        cover_href = cover_element.get(f"{{{XLINK_NAMESPACE}}}href")
        cover_id = cover_href.lstrip("#")  # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª "#"

        # –ù–∞—Ö–æ–¥–∏–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±–ª–æ–∂–∫–∏
        binary_element = root.find(f".//fb:binary[@id='{cover_id}']", namespaces=NAMESPACES)
        if binary_element is None:
            raise ValueError(f"–ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–ª–æ–∂–∫–∏ —Å id '{cover_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        binary_data = binary_element.text
        if not binary_data:
            raise ValueError("–ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±–ª–æ–∂–∫–∏ –ø—É—Å—Ç—ã.")

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º Base64 –≤ –±–∞–π—Ç–æ–≤—ã–π –æ–±—ä–µ–∫—Ç
        cover_bytes = base64.b64decode(binary_data)
        return cover_bytes
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –æ–±–ª–æ–∂–∫–∏: {e}")
        return None
    finally:
        file.seek(0)

def extract_metadata_from_fb2(file):
    try:
        ## –ü–∞—Ä—Å–∏–º XML –∏–∑ –±–∞–π—Ç–æ–≤
        #tree = ET.parse(file)
        #root = ET.parse(file).getroot()

        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        content = file.read()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É (–µ—Å–ª–∏ –Ω–µ UTF-8)
        try:
            xml_content = content.decode('utf-8')
        except UnicodeDecodeError:
            encoding = chardet.detect(content)['encoding'] or 'windows-1251'
            xml_content = content.decode(encoding, errors='replace')

        # –ü–∞—Ä—Å–∏–º XML —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            root = ET.fromstring(xml_content)
        except ET.ParseError:
            # –ü—Ä–æ–±—É–µ–º –ø–æ—á–∏–Ω–∏—Ç—å –±–∏—Ç—ã–π XML (–±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π)
            xml_content = xml_content.split('<?xml', 1)[-1]  # –£–¥–∞–ª—è–µ–º –≤—Å–µ –¥–æ <?xml
            xml_content = '<?xml' + xml_content.split('>', 1)[0] + '>' + xml_content.split('>', 1)[1]
            root = ET.fromstring(xml_content)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "title": None,
            "author": {
                "first_name": None,
                "last_name": None,
            },
            "publisher": None,
            "year": None,
            "city": None,
            "isbn": None,
        }

        # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
        title_element = root.find(".//fb:book-title", namespaces=NAMESPACES)
        if title_element is not None:
            metadata["title"] = title_element.text

        # –ê–≤—Ç–æ—Ä
        first_name_element = root.find(".//fb:author/fb:first-name", namespaces=NAMESPACES)
        if first_name_element is not None:
            metadata["author"]["first_name"] = first_name_element.text

        last_name_element = root.find(".//fb:author/fb:last-name", namespaces=NAMESPACES)
        if last_name_element is not None:
            metadata["author"]["last_name"] = last_name_element.text

        # –ò–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ
        publisher_element = root.find(".//fb:publish-info/fb:publisher", namespaces=NAMESPACES)
        if publisher_element is not None:
            metadata["publisher"] = publisher_element.text

        # –ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è
        year_element = root.find(".//fb:publish-info/fb:year", namespaces=NAMESPACES)
        if year_element is not None:
            metadata["year"] = year_element.text

        # –ì–æ—Ä–æ–¥
        city_element = root.find(".//fb:publish-info/fb:city", namespaces=NAMESPACES)
        if city_element is not None:
            metadata["city"] = city_element.text

        # ISBN
        isbn_element = root.find(".//fb:publish-info/fb:isbn", namespaces=NAMESPACES)
        if isbn_element is not None:
            metadata["isbn"] = isbn_element.text
        return metadata
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        return None
    finally:
        file.seek(0)

def format_metadata_message(metadata):
    if metadata:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        message_parts = []
        if metadata.get("publisher"):
            #message_parts.append(f"–ò–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ: {metadata['publisher']}")
            message_parts.append(f"{metadata['publisher']}")
        if metadata.get("year"):
            #message_parts.append(f"–ì–æ–¥: {metadata['year']}")
            message_parts.append(f"{metadata['year']}")
        if metadata.get("city"):
            #message_parts.append(f"–ì–æ—Ä–æ–¥: {metadata['city']}")
            message_parts.append(f"{metadata['city']}")
        if metadata.get("isbn"):
            #message_parts.append(f"ISBN: {metadata['isbn']}")
            message_parts.append(f"{metadata['isbn']}")
        message = ", ".join(message_parts)
    else:
        message = None
    return message

def remove_punctuation(text):
    if text is None:
        return None
    else:
        return re.sub(r'[^\w\s]', ' ', text)

def _get_reader_links_for_platform(platform: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —á–∏—Ç–∞–ª–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
    """
    if platform == 'android':
        return """
üì± <b>–ß–∏—Ç–∞–ª–∫–∏ –¥–ª—è Android:</b>
‚Ä¢ üìñ <a href="https://play.google.com/store/apps/details?id=org.readera">ReadEra</a> - –ª—É—á—à–∞—è –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è
‚Ä¢ üìö <a href="https://play.google.com/store/apps/details?id=com.flyersoft.moonreader">Moon+ Reader</a> - –º–æ—â–Ω–∞—è
‚Ä¢ üî• <a href="https://play.google.com/store/apps/details?id=com.amazon.kindle">Kindle</a> - –æ—Ç Amazon
‚Ä¢ üìì <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.playbooks">Google Play –ö–Ω–∏–≥–∏</a>
"""
    elif platform == 'ios':
        return """
üì± <b>–ß–∏—Ç–∞–ª–∫–∏ –¥–ª—è iOS:</b>
‚Ä¢ üìñ <a href="https://apps.apple.com/ru/app/readera-—á–∏—Ç–∞–ª–∫–∞-–∫–Ω–∏–≥-pdf/id1441824222">ReadEra</a>
‚Ä¢ üìö <a href="https://apps.apple.com/ru/app/kybook-3-ebook-reader/id1259787028">KyBook 3</a>
‚Ä¢ üî• <a href="https://apps.apple.com/ru/app/amazon-kindle/id302584613">Kindle</a>
‚Ä¢ üìì <a href="https://apps.apple.com/ru/app/apple-books/id364709193">Apple Books</a>
"""
    else:
        # –î–ª—è –¥–µ—Å–∫—Ç–æ–ø–æ–≤ –∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        return """
üíª <b>–ß–∏—Ç–∞–ª–∫–∏ –¥–ª—è –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º:</b>
‚Ä¢ üìñ <a href="https://play.google.com/store/apps/details?id=org.readera">ReadEra (Android)</a>
‚Ä¢ üìñ <a href="https://apps.apple.com/ru/app/readera-—á–∏—Ç–∞–ª–∫–∞-–∫–Ω–∏–≥-pdf/id1441824222">ReadEra (iOS)</a>
‚Ä¢ üìö <a href="https://www.calibre-ebook.com/">Calibre</a> - –¥–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞ (Windows/Mac/Linux)
‚Ä¢ üî• <a href="https://www.amazon.com/b?node=16571048011">Kindle</a> - –≤—Å–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
‚Ä¢ üìò <a href="https://apps.apple.com/ru/app/apple-books/id364709193">Apple Books</a> (Mac/iOS)
"""

def get_platform_recommendations() -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
    (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥, —Ç–∞–∫ –∫–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Å–ª–æ–∂–Ω–æ)
    """
    return """
üì± <b>–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —á–∏—Ç–∞–ª–∫–∏ –¥–ª—è –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º:</b>
<u>–î–ª—è Android:</u>
‚Ä¢ üìñ <a href="https://play.google.com/store/apps/details?id=org.readera">ReadEra</a> - –ª—É—á—à–∞—è –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è
‚Ä¢ üìö <a href="https://play.google.com/store/apps/details?id=com.flyersoft.moonreader">Moon+ Reader</a>
‚Ä¢ üî• <a href="https://play.google.com/store/apps/details?id=com.amazon.kindle">Kindle</a>

<u>–î–ª—è iOS:</u>
‚Ä¢ üìñ <a href="https://apps.apple.com/ru/app/readera-—á–∏—Ç–∞–ª–∫–∞-–∫–Ω–∏–≥-pdf/id1441824222">ReadEra</a>
‚Ä¢ üìö <a href="https://apps.apple.com/ru/app/kybook-3-ebook-reader/id1259787028">KyBook 3</a>
‚Ä¢ üî• <a href="https://apps.apple.com/ru/app/amazon-kindle/id302584613">Kindle</a>

<u>–î–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞:</u>
‚Ä¢ üìö <a href="https://www.calibre-ebook.com/">Calibre</a> (Windows/Mac/Linux)
‚Ä¢ üìò <a href="https://apps.apple.com/ru/app/apple-books/id364709193">Apple Books</a> (Mac)
‚Ä¢ üìñ <a href="https://www.amazon.com/b?node=16571048011">Kindle</a> (–≤—Å–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã)
"""


# ===== –°–õ–£–ñ–ï–ë–ù–´–ï –§–£–ù–ö–¶–ò–ò =====

async def download_book_with_filename(url: str):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∫–Ω–∏–≥—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ + –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    book_data = await response.read()
                    filename = None

                    content_disposition = response.headers.get('Content-Disposition', '')
                    if content_disposition:
                        filename_match = re.search(r'filename[^;=\n]*=([\'"]?)([^\'"\n]+)\1', content_disposition,
                                                   re.IGNORECASE)
                        if filename_match:
                            filename = unquote(filename_match.group(2))

                    return book_data, filename
                return None, None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∫–Ω–∏–≥–∏: {e}")
        return None, None


async def upload_to_tmpfiles(file, file_name: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞ tmpfiles.org –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    try:
        async with aiohttp.ClientSession() as session:
            form_data = aiohttp.FormData()
            form_data.add_field('file', file, filename=file_name)
            params = {'duration': '15m'}

            async with session.post(
                    'https://tmpfiles.org/api/v1/upload',
                    data=form_data,
                    params=params
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result['data']['url']
                return None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return None


# async def get_cover_url(book_id: str):
#     """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –æ–±–ª–æ–∂–∫–∏ —á–µ—Ä–µ–∑ BeautifulSoup"""
#     try:
#         url = f"{FLIBUSTA_BASE_URL}/b/{book_id}"
#         async with aiohttp.ClientSession() as session:
#             async with session.get(url) as response:
#                 if response.status == 200:
#                     html = await response.text()
#                     soup = BeautifulSoup(html, 'html.parser')
#                     cover_img = soup.find('img', title='Cover image')
#                     if cover_img and cover_img.get('src'):
#                         return urljoin(FLIBUSTA_BASE_URL, cover_img['src'])
#         return None
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±–ª–æ–∂–∫–∏: {e}")
#         return None
#
#
# async def download_cover(cover_url: str):
#     """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–±–ª–æ–∂–∫—É –ø–æ URL"""
#     try:
#         async with aiohttp.ClientSession() as session:
#             async with session.get(cover_url) as response:
#                 if response.status == 200:
#                     return await response.read()
#         return None
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ–±–ª–æ–∂–∫–∏: {e}")
#         return None
#
#
# async def download_book_from_flibusta(book_id: str, book_format: str):
#     """–°–∫–∞—á–∏–≤–∞–µ—Ç –∫–Ω–∏–≥—É —Å Flibusta.is"""
#     try:
#         url = f"{FLIBUSTA_BASE_URL}/b/{book_id}/{book_format}"
#         async with aiohttp.ClientSession() as session:
#             async with session.get(url) as response:
#                 if response.status == 200:
#                     return await response.read()
#         return None
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∫–Ω–∏–≥–∏: {e}")
#         return None


# # ===== DEEP LINK SEARCH =====
#
# def is_deeplink_search(args: list) -> bool:
#     """
#     –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å deep link –ø–æ–∏—Å–∫–æ–º
#     :param args: –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏–∑ context.args
#     :return: True –µ—Å–ª–∏ —ç—Ç–æ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
#     """
#     return bool(args)
#
#
# def parse_deeplink_params(args: list) -> dict:
#     """
#     –ü–∞—Ä—Å–∏—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ deep link
#     :param args: –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏–∑ context.args
#     :return: —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
#     """
#     params = {}
#
#     #debug
#     print(args)
#
#     for arg in args:
#         if '=' in arg:
#             key, value = arg.split('=', 1)
#             key_lower = key.lower()
#             params[key_lower] = urllib.parse.unquote(value)
#
#     return params
#
#
# def build_search_query(params: dict) -> str:
#     """
#     –°—Ç—Ä–æ–∏—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: –ª–∏–±–æ –∏–∑ q, –ª–∏–±–æ –∏–∑ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
#     """
#     # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ q
#     if 'q' in params:
#         return params['q']
#
#     # –ü–æ–∏—Å–∫ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
#     search_parts = []
#
#     for param_key, criterion in DEEPLINK_CRITERIA_MAPPING.items():
#         if params.get(param_key):
#             search_parts.append(f"{criterion}:{params[param_key]}")
#
#     return ", ".join(search_parts)
#
#
# def generate_search_deeplink(params: dict) -> str:
#     """
#     –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç deep link –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ URL
#     :param params: —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ {param: value}
#     :return: –≥–æ—Ç–æ–≤–∞—è —Å—Å—ã–ª–∫–∞
#     """
#
#     if not params:
#         return f"https://t.me/{BOT_USERNAME}"
#
#     query_params = []
#     for key, value in params.items():
#         if value:
#             encoded_value = urllib.parse.quote(str(value))
#             query_params.append(f"{key}={encoded_value}")
#
#     return f"https://t.me/{BOT_USERNAME}?{'&'.join(query_params)}"
